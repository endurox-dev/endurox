Migrating from Oracle Tuxedo to Enduro/X
========================================
:doctype: book

== About the guide

This document describes different aspects which needs to be accounted for
when performing migration from Oracle Tuxedo to Enduro/X middleware.
The document describes common elements which Enduro/X covers from Tuxedo
functionality, how functionality and configuration differs.

Lastly document describes standard approach for performing configuration
migration for Tuxedo UBB Config to Enduro/X based configuration

Document shall be read by anybody which is involved into migration project
from Oracle Tuxedo to Enduro/X middleware.

== Overview

Both systems are build on X/Open *XATMI*, *XA*, *TX* standards. Each of the systems
implement extensions over theses APIs. For example Tuxedo have *FML* key-value
structure format handling API. Enduro/X counterpart for this functionality is
*UBF* buffers which even provide emulation for *FML* via *fml.h* and *fml32.h*
headers shipped with Enduro/X.

Enduro/X tends to implement most majority of the C APIs which are typically used in
Tuxedo application. To verify your application compatibility with Enduro/X, 
perform manual scan over your code base and check each Tuxedo API in Enduro/X
documentation.

Enduro/X uses different configuration file formats than Tuxedo, however majority
of the configuration concepts are the same.

Enduro/X provides tool *tmloadcf(8)* which allows to automatically convert Tuxedo
UBB configuration.


== API compatibility aspects

Mostly all XATMI/FML calls are supported by Enduro/X with the same logic and
parameters. This section lists some (but not all) known differences:

- *tpgetctxt(3)* Enduro/X version after the call puts current thread outside
of any context association.


== Migration process
...

=== Automatic configuration migration
...

=== Manual configuration migration

Even if configuration is being migrated by automatic approach, it is worth to
read this section. This allows get solid understand of the Enduro/X concepts by using
existing Tuxedo knowledge.

If looking on Tuxedo UBBCONFIG and Enduro/X ndrxconfig.xml/app.ini, then following
similarities projects:

.UBBConfig - Enduro/X section mapping
[width="80%", options="header"]
|=========================================================
|Ubb config section|Enduro/X ndrxconfig.xml|Enduro/X app.ini|Comments
|*RESOURCES|-|[@global] section|Approximate mapping
|*MACHINES|-|[@global], [@debug] path related infos|Approximate mapping
|*GROUPS|-|[@global/<CCTAG>] - global settings per tag, [@queue/<CCTAG>] - persistent
queue configuration per tag.|Approximate mapping
|*NETWORK|Bridge is established as *tpbridge(8)* XATMI server 
processes in <servers> section|-|Approximate mapping
|*SERVERS|<endurox><servers> tag |-|-
|*SERVERS server|<endurox><servers><server name="server"> tag |-|-
|*SERVERS DEFAULT:|<endurox><defaults> tag |-|-
|*SERVICES|<endurox><services>|-|Service settings are global per instance, i.e.
cannot be configured per cctag.
|*SERVICES service|<endurox<services><service svcnm="service">|-|-
|*SERVICES DEFAULT:|<endurox><services><defaults>|-|-
|*ROUTING|<endurox><routing>|-|Defaults not supported at this section.
|*ROUTING route|<endurox><routing>/<route routing="route">|-|-
|=========================================================

.Tuxedo - Enduro/X key binaries mapping
[width="80%", options="header"]
|=========================================================
|Tuxedo binary|Enduro/X equivalent|Comments
|tmadmin|xadmin|There are set of common commands, like psc, start, etc.
|BBL, DBBBL|ndrxd|
|tlisten|tpbridge|Enduro/X binary is booted as a normal XATMI binary, i.e.
it is not required to start it before application boots
|TMSYSEVT,TMUSEREV|tpevsrv|Also Enduro/X event server is booted as a normal
XATMI binary.
|TMS|tmsrv|Enduro/X version of *tmsrv* supports loading XA switches via shared
libraries. So it is possible to configure *tmsrv* instances for different resources
without need to perform *buildtms(8)*. Enduro/X supports Tuxedo mode too, when
transaction manager is built for particular resource manager.
|=========================================================

=== Creating base configuration for Enduro/X

It is recommended to create base configuration for Enduro/X which is then amended
to match the migrated system setup.

In order to create a working instance of the Enduro/X application, you may use
following command:

--------------------------------------------------------------------------------

$ xadmin provision

--------------------------------------------------------------------------------

This will create base system layout, including directories and configuration files
such as:

- ndrxconfig.xml
- app.ini
- set (environment loader)

For further document we assume that system code "test1" is used.

=== UBB Configuration vs Enduro/X ini/xml format

*Tuxedo* use UBB configuration file, which is kind of extended ini file. This
describes majority of information used for Tuxedo application instance.

Other hand *Enduro/X* uses two separate files for the configuration. One is
XML configuration file (*ndrxconfig.xml(5)* typically) which describes the XATMI
server and client processes, services and DDR info. The other file is standard 
*ini* file (typically *app.ini*) which include per binary configuration.

Typically Enduro/X application are configure with third environment file
which loads the env variables in the shell session. File name typically
starts with *set*.

=== Converting "*RESOURCES" section

Enduro/X resources shall be configured according to the *ex_env(5)* manpage. This
section lists elements with the same or close meaning. Enduro/X setting
is written in *app.ini* in *[@global]* or *[@global/<CCTAG>]* section.

.Tuxedo - Enduro/X resources mapping
[width="80%", options="header"]
|=========================================================
|Tuxedo setting|Enduro/X equivalent|Comments
|IPCKEY|NDRX_IPCKEY|System wide IPC (shm, msg, sem) identifier offset.
This is hex value. For Enduro/X *0x* or *0X* prefix must not be present in value.
| MAXSERVERS | NDRX_SRVMAX | Max number of servers instance can handle
| MAXSERVICES | NDRX_SVCMAX | Max number of services instance can handle.
For Enduro/X bigger number (something like x2) is recommended, so that linear
hashing/service lookup would work faster.
|SCANUNIT, BLOCKTIME | NDRX_TOUT | In Enduro/X timeouts are configured in single
variable, set in seconds. Can be converted as NDRX_TOUT=(Tux SCANUNIT) * (Tux BLOCKTIME).
|SCANUNIT| NDRX_SCANUNIT| In case if using *SystemV* release (AIX pre 7.3, Solaris),
Enduro/X binaries internally by additional thread scan for timeouts in the local
process. The scanning is done by *NDRX_SCANUNIT* setting (in milliseconds), which
by default is *1000*. For Linux, FreeBSD, MacOS release these is not applicable.
|MAXRTDATA|NDRX_RTCRTMAX|Number of bytes available for routing criterion storage.
|=========================================================

=== Converting Tuxedo groups to Enduro/X CCTAGs

At Core of the *Tuxedo* application, principle of service grouping is used.
The grouping splits the binaries/servers in some logical groups. These
groups provides XA configuration per binary, also these groups internally
affect how XATMI IPC messages (such as *tpcall(3)*) land on the particular
server process instances.

In Enduro/X direct such grouping is not available, however Enduro/X have
common-configuration framework, which allows to bind different configuration
settings to binaries via *<cctag />* marking. Effectively, configuration
sub-sections may be used in similar way as Tuxedo groups. Via configuration
sub-sections following resources may be configured: *XA* configuration, *DDR*
routing. Normally *cctag* sub-section does not make server to participarte in
routing group, but within *[@global/<cctag>]* section parameter *NDRX_RTGRP*
may be set, which would make the process additionally advertise routing services.

However by using *cctag* settings, different settings from *ex_env(5)*
may be applied to set of the binaries, including timeouts, UBF/FML settings, etc.

Tuxedo's *SRVID* shall be unique within group, in Enduro/X *<srvid />* setting
must be unique at instance level.

=== Service dispatching

By default in Tuxedo, if *RQADDR* setting is not configured, each server have
it's own request queue, where then in round-robin or similar fashion requests
from ATMI clients are dispatched. If *RQADDR* is configured, then 
services may work in Multiple Servers, Single Queue (*MSSQ*) model. However,
here requirement is that these servers listening one queue have all the same
services.

In Enduro/X when working in Linux (and FreeBSD), by default all 
services operate in *MSSQ* mode. Basically in Enduro/X each service 
is queue were several executables perform epoll() + EPOLLEXCLUSIVE 
listing on messages. Result is that different servers may have
different sets of services (including shared set of services) and on these shared
services effectively *MSSQ* mode will work out-of-the-box.

On IBM AIX and Oracle Solaris *<rqaddr />* principle may be used in the same way
as Tuxedo does. For MacOS *<rqaddr />* is not available and request dispatching
is done in round-robin fashion only.

=== Clustering

In Enduro/X applications each instance works as "master" node, forming
a peer to peer cluster. This means that each cluster node needs to be started
separately in opposite to Tuxedo, where cluster application is started from
master node, and secondary nodes are started by the master.

Enduro/X cluster works in similar fashion as Tuxedo Gateway, except that
*tpforward(3)* and all other APIs work in the same mode as Tuxedo's multi-machine
configuration (i.e. MODEL=MP).

=== Cluster connectivity

In Tuxedo, on each server *tlisten* binary shall be started which listens for
any other node to connect. In Tuxedo this binary must be started before Tuxedo
is booted.

In Enduro/X each cluster link (between this and other nodes) must be defined in 
*<servers />* as a normal ATMI server. The server process is *tpbridge(8)*. In one
node listening/binding address/port must be set, in other node client mode shall
be configured to connect to first node.

If node *1* shall be connected to nodes *2* and *3*, then on node *1*, two 
*tpbridge* process shall be configured, to establish links to nodes *2* and *3*.

In Enduro/X cluster each server is identified with unique number in range for
1..32, set in *NDRX_NODEID* parameter. This similar to Tuxedo's *LMID*, but
value is strinctly limited to numbers only.

=== Transaction management

While both platforms provide distributed transaction processing APIs and both
perform according to X/Open XA protocol, internally architecture for both products
are different. Key aspects are mentioned here:

- Log format

- Transaction managers

- Recovery


== Tuxedo connectivity and bindings

- Enduro/X does not have *WebLogic Tuxedo Connector* or *Jolt* libraries
for Java. But Enduro/X provides Web Services interface module *endurox-connect*,
particularly *restincl(8)* from which XATMI services can be exposed as JSONS 
web services. With this Enduro/X services may be called from any language which supports web
services. Web services API provides capability for managing global transactions.

- Enduro/X counterpart to the Tuxedo *SALT* is endurox-connect module. The
*restincl(8)* serves the inbound web services traffic and *restousv(8)* services
the outbound traffic. The message formats between *SALT* and *endurox-connect*
are different. Enduro/X counter part tends to use *JSON* message formats. However
*restincl* is extensible and provides general purpose module for incoming
web traffic handling from XATMI perspective (this includes any kind of web traffic
handling, file upload, custom message formats, etc.).

- *endurox-java* package serves as direct counterpart of the *Oracle Tuxedo Java*. Some
of the APIs are different, but majority conforms to the *TJATMI*. Enduro/X implementation
is based on JNI binding code. Each java instance is started as separate binary.


////////////////////////////////////////////////////////////////
The index is normally left completely empty, it's contents being
generated automatically by the DocBook toolchain.
////////////////////////////////////////////////////////////////
