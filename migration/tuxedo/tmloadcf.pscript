//
// Ubb config to Enduro/X converter
//
// Some Caveats:
// - In Tuxedo srvid is per group setting. In Enduro/X this setting is per instance.
//   So in case if duplicate srvid's are detected, loader will allocate completely
//   new numbers.
// - Groups are not supported per service entry. Thus to affected machines
//   only first service entry is exported.


////////////////////////////////////////////////////////////////////////////////
// General constants
////////////////////////////////////////////////////////////////////////////////

//Base range for port number.
//Each machine shall be accessible in range of 21001..210NN (where NN max number of
//of cluster nodes).
//Converter from *NETWORK section does not extract ports, just hostnames
const NET_BASE_PORT = 21000;

//Host IP address (assumed) by + nodeid, range 200..2NN (where NN is max cluster node id
//Also assumed that hosts can reach each other by these addresses.
const NET_DEFAULT_IP_START=200;           //start IP of the nodes
const NET_DEFAULT_IP = "192.168.88.";

const IDFREE_SPACE  = 30;                 //Free srvids between new binaries, auto-assign

//Include wizard base.
compilestring(getwizardbase())();

////////////////////////////////////////////////////////////////////////////////
// UBB Config, functions called by tmloadcf as flex & bison parses.
////////////////////////////////////////////////////////////////////////////////

//
// Globals
//

//This will keep open handles
M_instances <- {};

//Mapping from [LMID] -> MACHINE entry
M_lmidmachines <- {};

M_wizzard <- WizardBase();

//
// Parsed UBB Config:
//
M_resources <- {};
M_sections <- {};

//Current values
M_cur_section <- {};
M_cur_default <- {};

//This is hash of arrays.
//For one parameter there may be actually several parameters with the same
//name
M_cur_param <- {};
M_values <- [];


//Folders for generation
//Each key is full path to the disk 
//with following attributes:
//.exists true|false
//.generated true|false
//Used on error termination to cleanup
M_folder_gen <- {};

//List of files generated
//Used on error termination to clean
M_files_gen <- [];

/**
 * Add resource/keyword value
 */
function tux_add_val(arg)
{
    M_values.append(arg);
}

/**
 * Add resource parameter
 */
function tux_add_res_parm(arg)
{
    M_resources[arg] <-M_values;
    M_values<-[]; //reset
}

/**
 * Add section parameter
 */
function tux_add_sect_parm(arg)
{
    local is_default=false;

    print("Adding param ["+arg+"]");

    if (arg == "DEFAULT:")
    {
        is_default=true;
    }

    param <- {};

    //Add link to previous default
    param.defaults <- M_cur_default;
    param.keywords <- {};
    param.name <- arg;
 
    //Refresh current default
    if (is_default)
    {
        param.is_default<-true;
        M_cur_default = param;
    }
    else
    {
        param.is_default<-false;
    }

    //Save current param
    M_cur_param = param;

    //Now this is array
    if (! (arg in M_cur_section.params))
    {
        M_cur_section.params[arg]<-[]
    }

    //Get this individual in the order
    M_cur_section.order.append(param);  
    //This is now array.
    M_cur_section.params[arg].append(param);

}

/**
 * Mark group as participating in routing
 */
function tux_mark_group_routed(arg)
{
    if (arg in M_sections["*GROUPS"].params 
            && !( "routed" in M_sections["*GROUPS"].params[arg]))
    {
        M_sections["*GROUPS"].params[arg][0].routed<-true;
        print("GROUP ["+arg+"] -> routed");
    }
}

/**
 * Add keyword to parameter, callback
 */
function tux_add_sect_keyw(arg)
{   
    M_cur_param.keywords[arg] <- M_values;

    if (M_cur_section.name == "*ROUTING" && arg=="RANGES")
    {
        //Parse the DDR range.
        tux_ddr_parse(M_values[0]);
    }

    M_values<-[];
}

/**
 * Add section, callback
 */
function tux_add_sect(arg)
{
    M_sections[arg] <- {};
    M_sections[arg].params <- {};
    M_sections[arg].name <- arg;
    M_sections[arg].order <- [];

    M_cur_default <- {};
    M_cur_section = M_sections[arg];
    M_cur_param  <- {};
}

////////////////////////////////////////////////////////////////////////////////
// Generator section
////////////////////////////////////////////////////////////////////////////////


/**
 * Additional initializations
 */
function init()
{
    M_wizzard.qpath = "/dev/mqueue";
    if ("FREEBSD"==getosname())
    {
        M_wizzard.qpath = "/mnt/mqueue";
    }
}

/**
 * Get default value for section param.
 * Note that platformscript does not allow to use identifier "default" as
 * variable name.
 * @param param param object of the section
 * @param keyword keyword of interest
 * @param stock_default stock default value (if param value not present, and any
 * chained default value is not found
 * @return action value read
 */
function get_val(param, keyword, stock_default)
{
    if (! (keyword in param.keywords))
    {
        //Lookup in reverse order from current default
        local dflt = param.defaults;

        while (("keywords" in dflt) && !(keyword in dflt.keywords))
        {
            //Step back to previous default
            if ("defaults" in dflt)
            {
                dflt = dflt.defaults;
            }
            else
            {
                //No more defaults in the section
                break;
            }
        }

        if ("keywords" in dflt && keyword in dflt.keywords)
        {
            return dflt.keywords[keyword];
        }
        else
        {
            if (stock_default==null)
            {
                throw("No stock "+keyword+" value available for param ["+param.name+"]");
            }
            return stock_default;
        }
    }
    else
    {
        return param.keywords[keyword];
    }
}

/**
 * Return number of services for instance used for routing
 * @param instance instance of interest
 * @return max number of routing services used
 */
function get_routing_services(instance)
{
    local cnt=0;

    if ("*SERVICES" in M_sections)
    {
        foreach(idx,service in M_sections["*SERVICES"].order)
        {
            if (!service.is_default)
            {
                local range = {};
                local service_srvgrp = get_val(service, "SRVGRP", "");
                
                //Service may have no group -> affect all
                if (service_srvgrp =="")
                {
                    cnt++;
                }
                else
                {
                    local group_lmid = get_val(
                        M_sections["*GROUPS"].params[service_srvgrp[0]][0], "LMID", null)[0];

                    if (group_lmid == instance.lmid)
                    {
                        cnt++;
                    }

                }
            }
        }
    }
    print("Routing services: "+cnt);
    return cnt;
}

/**
 * Reserve number of slots in free ranges
 * remove those ranges from next time use.
 * @param instance current machine instance we are generating
 * @slots number of slots required
 * @return start index that is guaranteed to have + (slots-1) free
 *  places.
 */
function reserve_range(instance, slots)
{
    local ret = 0;

    foreach(idx,range in instance.free_ranges)
    {
        if (range.min + (slots-1) <= range.max)
        {
            ret=range.min;
            //Reduce
            range.min=range.min+slots;
            
            if (range.min>range.max)
            {
                instance.free_ranges.remove(idx);
            }
            break;
        }
    }

    if (0==ret)
    {
        throw("Cannot find free binary range for number of "+slots+" slots");
    }

    return ret;
}

/**
 * Prepare free ID ranges for given instance. For upper number we take
 *  number of total servers + 2000.
 * @param instance instance of interest
 */
function prep_free_ranges(instance)
{
    //We need to register all ranges
    //All ranges must be sorted
    //The free interval must be detected
    local start = 1;
    instance.ranges<-[];

    if ("*SERVERS" in M_sections) foreach(idx,server in M_sections["*SERVERS"].order)
    {
        if (!server.is_default)
        {
            local range = {};
            local server_srvgrp = get_val(server, "SRVGRP", "");
            local group_lmid = get_val(
                M_sections["*GROUPS"].params[server_srvgrp[0]][0], "LMID", null)[0];

            if (group_lmid == instance.lmid)
            {
                //OK this is our server
                range.min <-get_val(server, "MIN", ["1"]);
                range.max <-get_val(server, "MAX", range.min);
                range.srvid <-get_val(server, "SRVID", "");

                if (range.max[0].tointeger() < range.min[0].tointeger())
                {
                    throw(format("Invalid server %s range min=%d > max=%d",
                            server.name, range.min[0].tointeger()
                            , range.max[0].tointeger()));
                }
                range.min = range.min[0].tointeger()+range.srvid[0].tointeger();
                range.max = range.max[0].tointeger()+range.srvid[0].tointeger();
                    
                //print(format("Used rang srvid: %s %d - %d", 
                //    range.srvid[0], range.min[0], range.max[0]));
                instance.ranges.append(range);
            }
        }    
    }

    instance.ranges.sort(@(a,b) a.min <=> b.min);
    instance.free_ranges <- [];

    foreach(idx,range in instance.ranges)
    {
        print(format("Used range %d - %d", 
                range.min, range.max));
    }

    //Add first range if any
    local len = instance.ranges.len();
    if (len > 0)
    {
        if (instance.ranges[0].min > 1)
        {
            local fr = {};
            fr.min <- 1;
            fr.max <- (instance.ranges[0].min - 1);
            instance.free_ranges.append(fr);
        }

        local i=0;
        for (; i<len-1; i++)
        {
            if (instance.ranges[i].max+1< instance.ranges[i+1].min)
            {
                local fr = {};
                fr.min <- (instance.ranges[i].max   + 1);
                fr.max <- (instance.ranges[i+1].min - 1);
                instance.free_ranges.append(fr);
            }
        }

        //Add some free range+10K
        local fr = {};
        fr.min <- (instance.ranges[i].max   + 1);
        fr.max <- (instance.ranges[i].max   + 1 + 10000);
        instance.free_ranges.append(fr);
    }
    else
    {
        local fr = {};
        fr.min <- 1;
        fr.max <- 10000;
        instance.free_ranges.append(fr);
    }

    foreach(idx,range in instance.free_ranges)
    {
        print(format("Free range %d - %d", 
                range.min, range.max));
    }

}

/**
 * Prepare groups of interest for this particular node.
 * Mark the group is it used or not (used if routed or have xa).
 * Prepare open/close infos / xa infos, (extract xa settings).
 */
function prep_groups(instance)
{
    foreach(idx,igroup in M_sections["*GROUPS"].params)
    {
        //Single group only supported...
        local group = igroup[0];
        //Get our groups
        if ( !group.is_default && (get_val(group, "LMID", null)[0] == instance.lmid))
        {
            group.plot<-false;
            group.tmsrv_plotted<-false;

            if ("OPENINFO" in group.keywords)
            {
                //Mark that this instance uses xa.
                instance.xa_used<-true;

                group.rmid <- get_val(group, "GRPNO", null)[0];
                local openinfo = get_val(group, "OPENINFO", null)[0];

                //Get the Switch name
                local ex = regexp(@"^(.*):.*");

                local res = ex.capture(openinfo)[1];

                group.xaswitchname <-openinfo.slice(res.begin, res.end);

                print("Got switch: ["+group.xaswitchname+"]");
                
                if (group.xaswitchname== "TUXEDO/QM")
                {
                    //Special case for MQ
                    //We only need Qspace name, the data will be stored
                    // in app_home/qdata/rm<rmid>

                    ex = regexp(@"^.*:.*:(.*)");
                    res = ex.capture(openinfo)[1];
                    local qspace = openinfo.slice(res.begin,res.end);
                    group.openinfo <- "datadir=\"${NDRX_APPHOME}/qdata/"+qspace+"\",qspace=\""+qspace+"\"";
                    group.closeinfo <- "${NDRX_XA_OPEN_STR}";
                    
                    //Schedule folder for creation.
                    if ( !(instance.app_home+"/qdata" in M_folder_gen))
                    {
                        M_folder_gen[instance.app_home+"/qdata"]<-{};
                    }
                    group.qspace<-qspace;
                    group.data_folder <- instance.app_home+"/qdata/"+qspace;
                    M_folder_gen[group.data_folder]<-{};

                    //Hashmap of auto-queues served by given queue space
                    //internally may contains .trantime setting override.
                    group.auto_queues<-{};
                    group.workers<-0;

                }
                else
                {
                    ex = regexp(@"^.*:(.*)");
                    res = ex.capture(openinfo)[1];
                    //Extract the values, transform the "TUXEDO/QM"
                    group.openinfo <- openinfo.slice(res.begin,res.end);
                    local closeinfo = get_val(group, "CLOSEINFO", [""])[0];
                    
                    if (closeinfo=="")
                    {
                        group.closeinfo <- "${NDRX_XA_OPEN_STR}";
                    }
                    else
                    {
                        ex = regexp(@"^.*:(.*)");
                        res = ex.capture(closeinfo)[1];
                        group.closeinfo <- closeinfo.slice(res.begin,res.end);
                    }
                }

                //Schedule folders to be created
                if ( !(instance.app_home+"/tmlogs" in M_folder_gen))
                {
                    M_folder_gen[instance.app_home+"/tmlogs"]<-{};
                }

                group.tmlogs<-instance.app_home+"/tmlogs/rm"+group.rmid;
                M_folder_gen[group.tmlogs]<-{};

            }

        }
    }
}

/**
 * Merge defaults for current instance
 */
function merge_defaults(instance)
{
    local prev_server={};
    prev_server.is_default<-false;
    foreach (idx, server in instance.servers)
    {
        //If current one is default and previous is also de
        if (server.is_default && prev_server.is_default)
        {
            //Copy all current server attribs over prev_server
            //and delete curren entry.
            foreach (idx, keyword in server)
            {
                prev_server[idx]<-server[idx];
            }
            //Remove current entry...
            instance.servers[idx].deleted<-true;
        }
        else
        {
            //Ensure deleted tags
            if (!("deleted" in instance.servers[idx]))
            {
                instance.servers[idx].deleted<-false;
            }
            prev_server = server;
        }
        
        //Mark group used...
        if ("SRVGRP" in server)
        {
            M_sections["*GROUPS"].params[server["SRVGRP"]][0].plot<-true;
        }
    }
    
}

/**
 * Prepare binaries:
 * For this LMID:
 * Remove: WSL/TMSYSEVT/JSL/TMMETADATA/TMFAN/TMQFORWARD
 * Mark: if found TMSYSEVT or TMUSREVT -> tpevsrv needed.
 * Mark: If WSL or JSL used -> restincl needed (incl clients section) & cpmsrv
 * Extract: Group qspace shall be appended with automatic Qs from TMQFORWARD instances.
 * Transform: If for server -A is found, remove it. If -A is not found, add -N
 *  as Enduro/X advertises all by default.
 * Transform: TMQUEUE -> tmqueue, replace min/max=1, update clopt.
 */
function prep_servers(instance)
{
    local server_optstring = "Aa:s:e:Ghl:n:o:Pp:rtv";

    // phase 1. Get infos about the system
    if ("*SERVERS" in M_sections) foreach(idx,server in M_sections["*SERVERS"].order) if (!server.is_default)
    {
        local server_srvgrp = get_val(server, "SRVGRP", null);
        local group_lmid =get_val(M_sections["*GROUPS"].params[ server_srvgrp[0] ][0], "LMID", null)[0];

        if (group_lmid == instance.lmid)
        {
            local remove = false;
            print("Processing binary: ["+server.name+"]");
            
            /* Detect the type of the binary */

            switch(server.name)
            {
                case "WSL":
                case "JSL":
                        instance.restin<-true;
                        remove=true;
                    break;
                case "TMSYSEVT":
                case "TMUSREVT":
                        instance.events<-true;
                        remove=true;
                    break;
                case "TMMETADATA":
                case "TMFAN":
                        remove=true;
                    break;
                case "TMQUEUE":
                    //Translate to tmqueue
                    server.name="tmqueue";
                    server.keywords["MIN"]<-["1"];
                    server.keywords["MAX"]<-["1"];
                    //Match the forwarders at plotting, by group lookup...
                    server.keywords["CLOPT"]<-["-A -e ${NDRX_APPHOME}/log/tmqueue.${NDRX_SVSRVID}.log -r -- -s1 -p10"];
                    
                    break;
                case "TMQFORWARD":

                        remove=true;
                        
                        local group = M_sections["*GROUPS"].params[server_srvgrp[0]][0];
                        //Parse the group of the forward
                        //and parse the clopt of forward, so that we get
                        //queue name & 
                        //Extract min setting (used to set workers for the Q)
                        //Extract -t from clopt second group
                        //Extract -q Q1,Q2,etc. from clopt second group
                        
                        local fwd_min = get_val(server, "MIN", null)[0];
                        local fwd_clopt = get_val(server, "CLOPT", null)[0];
                            
                        //server opt string + tmqforward optstring
                        local clopt_parsed = parseclopt2(fwd_clopt, 
                                server_optstring, "q:t:ib:ednf:");

                        //assume -1 no special timeout used.
                        local trantime = "-1";

                        foreach(idx,opt in clopt_parsed.args2)
                        {
                            if (opt.opt=="t")
                            {
                                trantime= opt.val;
                                break;
                            }
                        }

                        foreach(idx,opt in clopt_parsed.args2)
                        {
                            if (opt.opt=="q")
                            {
                                //Split Q by ,
                                //And load each Q
                                local qs = split(opt.val, ",");
                                foreach (idx, qq in qs)
                                {  
                                    //Must be loaded.
                                    print(format("Adding Q [%s] to group [%s] trantime: %s",
                                                qq, group.name, trantime));
                                    group.auto_queues[qq]<-{};
                                    group.auto_queues[qq].queue<-qq;
                                    group.auto_queues[qq].trantime<-trantime;
                                    group.auto_queues[qq].workers<-fwd_min;
                                    group.workers+=fwd_min.tointeger();
                                }
                            }
                        }
                    break;
            }

            //do not process the deleted servers
            if (remove)
            {
                server.deleted<-true;
            }
            
        }   
    }


    // phase 2. Prepare binaries into instance.servers array, each element is hash with
    // key settings for the server or default to be generated.
    instance.servers<-[]

    local new_srv = {};
    
    //Add some reasonable defaults (mainly required by Enduro/X
    //and may be merged later if we get some further defaults
    new_srv.min<-1;
    new_srv.max<-1;
    new_srv.autokill<-1;
    new_srv.start_max<-10;
    new_srv.pingtime<-100;
    new_srv.ping_max<-800;
    new_srv.end_max<-10;
    new_srv.killtime<-1;
    new_srv.respawn<-"Y";
    new_srv.is_default<-true;
    instance.servers.append(new_srv);

    //Add common configuration server
    new_srv = {};
    new_srv.bin<-"cconfsrv";
    new_srv.srvid <- reserve_range(instance, 2);
    new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/cconfsrv.${NDRX_SVSRVID}.log -r";
    new_srv.min<-2;
    new_srv.max<-2;
    new_srv.is_default<-false;
    instance.servers.append(new_srv);

    //Add tpadmin server
    new_srv = {};
    new_srv.bin<-"tpadmsv";
    new_srv.srvid <- reserve_range(instance, 2);
    new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/tpadmsv.${NDRX_SVSRVID}.log -r";
    new_srv.min<-2;
    new_srv.max<-2;
    new_srv.is_default<-false;
    instance.servers.append(new_srv);

    //Add event server if used.
    if ("events" in instance)
    {
        new_srv = {};
        new_srv.bin<-"tpevsrv";
        new_srv.srvid <- reserve_range(instance, 1);
        new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/tpevsrv.${NDRX_SVSRVID}.log -r";
        new_srv.min<-1;
        new_srv.max<-1;
        new_srv.is_default<-false;
        instance.servers.append(new_srv);
    }

    //Add networking if used.
    if ( instance.machine.networked)
    {
        //link this machine with other networked machines.
        //the order of the machines
        //lets without -f, add manually if different architecture hosts
        //have been found.
        foreach(idx,val in M_sections["*MACHINES"].params) 
        {
            local machine = val[0];

            if (machine.is_default || !machine.networked)
            {
                continue;
            }

            local lmid  = machine.keywords.LMID[0];

            new_srv = {};
            new_srv.bin<-"tpbridge";
            new_srv.srvid <-reserve_range(instance, 1);
            new_srv.min<-1;
            new_srv.max<-1;
            new_srv.is_default<-false;

            if (machine.nodeid < instance.nodeid)
            {
                //In this case we take passive role and accept incoming connections
                new_srv.sysopt<-("-e ${NDRX_APPHOME}/log/tpbridge."+machine.nodeid+ "."+instance.nodeid+".log");

                new_srv.appopt<-"-n"+machine.nodeid+" -r -i 0.0.0.0 -p "
                        +(NET_BASE_PORT+machine.nodeid)+" -tP -z30";

                instance.servers.append(new_srv);
            }
            else if (machine.nodeid > instance.nodeid)
            {

                //This is active role, we connect 
                new_srv.sysopt<-"-e ${NDRX_APPHOME}/log/tpbridge." 
                        +machine.nodeid+ "."+instance.nodeid+".log";

                if ("ip" in machine)
                {
                    new_srv.appopt<-"-n"+machine.nodeid+" -r -i "+machine.ip+" -p "
                        +(NET_BASE_PORT+machine.nodeid)+" -tA -z30";
                }
                else
                {
                    new_srv.appopt<-"-n"+machine.nodeid+" -r -h "+machine.host+" -p "
                        +(NET_BASE_PORT+machine.nodeid)+" -tA -z30";
                }

                instance.servers.append(new_srv);
            }
        }
    }
    
    //loop over the binaries & defaults, if not deleted, add (for our instance)
    if ("*SERVERS" in M_sections) foreach(idx,server in M_sections["*SERVERS"].order) if (! ("deleted" in server))
    {
        local proceed=false;
        local server_srvgrp = "";
        local group = {};
        if (server.is_default)
        {
            //Any default is OK
            proceed=true;
        }
        else
        {
            server_srvgrp = get_val(server, "SRVGRP", null)[0];
            group = M_sections["*GROUPS"].params[server_srvgrp][0];
            local group_lmid =get_val(group, "LMID", null)[0];
            if (group_lmid==instance.lmid)
            {
                proceed=true;
            }
        }
        
        if (proceed)
        {
            //Process the binary, add to arrays...
            new_srv = {};
            
            if (server_srvgrp!="")
            {
                new_srv.srvgrp <-server_srvgrp;
                new_srv.group<-group;
            }

            new_srv.bin <- server.name;
            new_srv.is_default <- server.is_default;
            
            if (!new_srv.is_default)
            {
                //Load clopt & app opt
                local clopt = get_val(server, "CLOPT", null)[0];
                local clopt_parsed = parseclopt1(clopt, server_optstring);
                local have_A=false;
                local have_e=false;
                local sysopt = "";
                local appopt = "";

                //Check is -A not present, if so then we need to set -N
                foreach(idx,opt in clopt_parsed.args1)
                {
                    if (opt.opt=="A")
                    {
                        have_A=true;
                    }
                    
                    if (opt.opt=="e")
                    {
                        have_e=true;
                    }
                }
                
                if (!have_A)
                {
                    sysopt = "-N";
                }

                //Add -e file to write the stderr to log files.
                if (!have_e)
                {
                    if (sysopt!="")
                    {
                        sysopt= sysopt + " " + "-e ${NDRX_APPHOME}/log/"+new_srv.bin+".${NDRX_SVSRVID}.log"; 
                    }
                    else
                    {
                        sysopt= "-e ${NDRX_APPHOME}/log/"+new_srv.bin+".${NDRX_SVSRVID}.log"; 
                    }
                }

                //If string contains tab, space or newline - add quotes
                //For both sysopt and appopt.

                //Now generate clopt...
                foreach(idx,opt in clopt_parsed.args1) if (opt.opt != "A")
                {
                    if (sysopt=="")
                    {
                        sysopt="-"+opt.opt;
                    }
                    else
                    {
                        sysopt=sysopt + " -"+opt.opt;
                    }
                    if ("val" in opt)
                    {
                        //TODO: Escape " if found
                        if (null!=opt.val.find(" ") || null!=opt.val.find("\n") || null!=opt.val.find("\t"))
                        {
                            sysopt=sysopt + " \"" + opt.val + "\"";
                        }
                        else
                        {
                            sysopt=sysopt + " " + opt.val;
                        }
                    }
                }

                //Generate app opts
                foreach(idx,opt in clopt_parsed.freeargs)
                {
                    if (appopt=="")
                    {
                        appopt=opt;
                    }
                    else
                    {
                        //TODO: Escape " if found
                        if (null!=opt.find(" ") || null!=opt.find("\n") || null!=opt.find("\t"))
                        {
                            appopt=appopt + " \"" + opt + "\"";
                        }
                        else
                        {
                            appopt=appopt + " " + opt;
                        }
                    }
                }
                
                print("Built sysopt ["+sysopt+"]");
                print("Built appopt ["+appopt+"]");
                new_srv.sysopt <- sysopt;
                new_srv.appopt <- appopt;
            }

            if ("SRVGRP" in server.keywords)
            {
                new_srv.cctag<-server.keywords.SRVGRP[0];
            }

            if ("SRVID" in server.keywords)
            {
                new_srv.srvid<-server.keywords.SRVID[0];
            }

            if ("MIN" in server.keywords)
            {
                new_srv.min<-server.keywords.MIN[0];
            }

            if ("MAX" in server.keywords)
            {
                new_srv.max<-server.keywords.MAX[0];
            }
                
            if (!server.is_default)
            {
                //resolve min/max for final check
                new_srv.real_min <- get_val(server, "MIN", null)[0].tointeger();
                new_srv.real_max <-  get_val(server, "MAX", null)[0].tointeger();
            }

            if ("ENVFILE" in server.keywords)
            {
                new_srv.env<-server.keywords.ENVFILE[0];
            }

            //Not used on Linux
            if ("RQADDR" in server.keywords)
            {
                new_srv.rqaddr<-server.keywords.RQADDR[0];
            }
            
            if ("RESTART" in server.keywords)
            {
                new_srv.respawn<-server.keywords.RESTART[0];
            }

            if ("MAXDISPATCHTHREADS" in server.keywords)
            {
                new_srv.maxdispatchthreads<-server.keywords.MAXDISPATCHTHREADS[0];
            }

            if ("MINDISPATCHTHREADS" in server.keywords)
            {
                new_srv.mindispatchthreads<-server.keywords.MINDISPATCHTHREADS[0];
            }

            //THREADSTACKSIZE this goes to process, thus read value from defaults...
            local stacksz = get_val(server, "THREADSTACKSIZE", ""); 

            if (stacksz!="")
            {
                //Our stack is in KB
                new_srv.threadstacksize<- (stacksz[0].tointeger() / 1024);
            }
            
            instance.servers.append(new_srv);
        }

    }

    if (instance.xa_used || instance.restin)
    {
        //Add new defaults, do not re-use cctag
        new_srv={};
        new_srv.min<-1;
        new_srv.max<-1;
        new_srv.respawn<-"Y";
        new_srv.is_default<-true;
        new_srv.cctag<-"/"; //Use root global settings
        instance.servers.append(new_srv);

        if (instance.xa_used)
        {
            //Add new defaults, do not re-use cctag
            new_srv={};
            new_srv.bin <- "tmrecoversv";
            new_srv.srvid <- reserve_range(instance, 1);
            new_srv.real_min<-1;
            new_srv.real_max<-1;
            new_srv.is_default<-false;
            new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/tmrecoversv.log -r";
            new_srv.appopt <- "-p -s10";
            new_srv.cctag<-"/"; //Allow merge
            instance.servers.append(new_srv);
        }

        if (instance.restin)
        {
            //Add new defaults, do not re-use cctag
            new_srv={};
            new_srv.bin <- "cpmsrv";
            new_srv.srvid <- reserve_range(instance, 1);
            new_srv.real_min<-1;
            new_srv.real_max<-1;
            new_srv.is_default<-false;
            new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/cpmsrv.log -r";
            new_srv.appopt <- "-k3 -i1";
            new_srv.cctag<-"/"; //Allow merge
            instance.servers.append(new_srv);
        }
    }


    //phase 4. Merge consecutive defaults, remove last default if no binaries follow
    merge_defaults(instance);

    //OK Ready to plot debug, forward queues, server defaults + servers.
    local servers_final=[];

    // Copy all servers to final list
    // in case if xa is used, add tmsrv firstly
    foreach (idx, server in instance.servers)
    {
        //Check does this depend on XA group?
        //srvgrp is for translated binaries. which basically pull in the tmsrv
        if (!server.is_default && "srvgrp" in server &&
                !server.deleted)
        {
            local group = M_sections["*GROUPS"].params[ server.srvgrp ][0];
            local tmscout =get_val(group, "TMSCOUNT", [""])[0];
            
            //This is tmsrv group
            if ("xaswitchname" in group && !group.tmsrv_plotted)
            {
                local cnt = 1;
                if (tmscout!="")
                {
                    cnt = tmscout.tointeger();
                }
                //Add tmsrv here
                //Keep the same group setting
                //either direct cctag (if set) or then it must come from
                //the default.
                new_srv = {};

                
                if (group.xaswitchname== "TUXEDO/QM")
                {
                    new_srv.bin<-"tmsrv";
                }
                else
                {
                    new_srv.bin<-get_val(group, "TMSNAME", null)[0];
                }

                new_srv.srvid <- reserve_range(instance, cnt);
                new_srv.sysopt <- "-e ${NDRX_APPHOME}/log/tmsrv.${NDRX_SVSRVID}.log -r";
                new_srv.appopt <- "-t1 -l"+group.tmlogs;
                new_srv.min<-cnt;
                new_srv.max<-cnt;
                if ("cctag" in server)
                {
                    new_srv.cctag = server.cctag;
                }
                new_srv.is_default<-false;
                group.tmsrv_plotted=true;
                servers_final.append(new_srv);
            }

            //perform correction on tmq so that forward thread pool
            if (server.bin=="tmqueue")
            {
                //get the group & forwarder count
                //workers
                local workers = server.group.workers;

                if (workers<10)
                {
                    workers=10;
                }

                server.appopt+=" -f"+workers;
            }
        }

        if (!server.deleted)
        {
            servers_final.append(server);
        }
    }

    instance.servers = servers_final;

    //Remove any un-needed defaults from the end
    local len = instance.servers.len();
    
    for (local i=len-1; i>=0; i--)
    {
        local server = instance.servers[i];
        if (server.is_default)
        {
            instance.servers.remove(i);
        }
        else
        {
            break;
        }
    }

    //mark groups to plot
    foreach (idx, server in instance.servers)
    {
        if ("group" in server)
        {
            server.group.plot=true;
        }
    }

    //Merge from bellow to to up.
    //if all servers bellow default have the same group and default have also
    //group set, then set common group in the default and clear the cctag
    //setting from bellow servers
    local len = instance.servers.len();
    local last_cctag = "";
    local first = false;
    local continue_till_default = false;
    local matching_servers = [];

    for (local i=len-1; i>=0; i--)
    {
        local server = instance.servers[i];

        if (i==len-1)
        {
            first=true;
        }

        if (server.is_default)
        {
            if (!continue_till_default && last_cctag!="")
            {
                //Merge the cctag to default
                server.cctag<-last_cctag;
                //Remove default from all linked servers
                
                foreach (idx, sv in matching_servers)
                {
                    delete sv.cctag;
                }

            }
            else
            {
                //If and there is no default cctag for this default
                //then stop merging.
                //Because then further default merges might affect this particular
                //group and following binaries (i.e. get cctag from previous default)
                //Thus stop merging here.
                break;
            }

            first = true;
            last_cctag="";
            matching_servers = [];
        }
        else if (continue_till_default)
        {
            continue;
        }
        else if ("cctag" in server)
        {
            if (first)
            {
                last_cctag = server.cctag;
                //Append in case if we want to merge the group...
                matching_servers.append(server);
            }
            else if (last_cctag != server.cctag)
            {
                last_cctag="";
                continue_till_default=true;
            }
        }
        else
        {
            continue_till_default=true;
        }
    }

    //Verify server IDs
    local id_check = {};
    local have_dup = false;

    foreach (idx, server in instance.servers)
    {
        if (server.is_default)
        {
            continue;
        }

        local min = 0;
        local max = 0;

        if ("min" in server)
        {
            min = server.min;
            //For further processing
            server.real_min<-min;
        }
        else
        {
            min = server.real_min;
        }

        if ("max" in server)
        {
            max = server.max;
            //For further processing
            server.real_max<-max;
        }
        else
        {
            max = server.real_max;
        }

        print("BIN "+server.bin+" srvid="+server.srvid+" max="+max);

        for (local i=server.srvid.tointeger(); i<server.srvid.tointeger()+max.tointeger(); i++)
        {
            print("Check: "+i);
            if (i in id_check)
            {
                error("Got duplicate id ["+i+"] -> fallback to new assign");
                have_dup = true;
                //break; keep looping needs to setup all real_max
            }
            
            id_check[i]<-true;
        }

    }

    //IDFREE_SPACE
    //Loop over the all binaries 
    local srvid_base=1;
    if (have_dup || "1"== M_a_opt)
    {
        print("Assigning new numbers...");
        foreach (idx, server in instance.servers)
        {
            if (server.is_default)
            {
                continue;
            }
            
            server.srvid=srvid_base;
            srvid_base+=(server.real_max.tointeger()+IDFREE_SPACE);
        }
    }

}

/**
 * prepare networking. This will update each
 * As we need range of ports. we will extract only ip address from.
 * IPv6 recognition during migration currently is not supported (just add manually
 * to the tpbridge)
 * machine with LMID with ip/host/binding port information
 */
function prep_networking()
{   
    if (!("*NETWORK" in M_sections))
    {
        return;
    }
     
    // Assign each ip addr/or hostname, and add networked param
    foreach(idx,net in M_sections["*NETWORK"].params) if (!net[0].is_default)
    {
        local net = net[0];
        local naddr = get_val(net, "NADDR", null)[0];
        print(format("parsing lmid=[%s] naddr=[%s]", net.name, naddr));
        M_lmidmachines[idx].networked<-true;

        if (regexp("^//[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}:.*").match(naddr))
        {
            local ex = regexp("^//([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3}):.*");
            local res = ex.capture(naddr);
            local ip = naddr.slice(res[1].begin,res[1].end)+"."+
                        naddr.slice(res[2].begin,res[2].end)+"."+
                        naddr.slice(res[3].begin,res[3].end)+"."+
                        naddr.slice(res[4].begin,res[4].end);
            print("Extract by ip: "+ip);
            M_lmidmachines[idx].ip <- ip;
            
        }
        else if (regexp("^//.*:.*").match(naddr))
        {
            local ex = regexp(@"^//(.*):.*");
            local res = ex.capture(naddr);
            local hostname = naddr.slice(res[1].begin,res[1].end);
            print("Extract by hostname: "+hostname);
            M_lmidmachines[idx].hostname <- hostname;
        }
        /* extract by hex */
        else if (regexp("^//[xX]0002[0-9A-Fa-f]{12}").match(naddr)
                || regexp("^0[xX]0002[0-9A-Fa-f]{12}").match(naddr))
        {
            local hex_str = "";
            
            if ("//"==substr(naddr, 0, 2))
            {
                // //x0002 or //X0002
                hex_str=substr(naddr, 7, -1);
            }
            else
            {
                // 0x0002 or 0X0002
                hex_str=substr(naddr, 6, -1);
            }
            print("Got hex ip: [" +hex_str+ "]");
            
            local ex = regexp("^....(..)(..)(..)(..)");
            local res = ex.capture(naddr);
            local ip =  hex2int(hex_str.slice(res[1].begin,res[1].end)) + "." +
                        hex2int(hex_str.slice(res[2].begin,res[2].end)) + "." +
                        hex2int(hex_str.slice(res[3].begin,res[3].end)) + "." +
                        hex2int(hex_str.slice(res[4].begin,res[4].end));
            print("Extract by hex-ip: "+ip);
            M_lmidmachines[idx].ip <- ip;
        }
        else
        {
            
            local ip_start = NET_DEFAULT_IP_START + M_lmidmachines[idx].nodeid;
            local ip = "192.168.88."+ip_start;
            print("Use default addresses: "+ip);
            M_lmidmachines[idx].ip <- ip;
        }
	
    }

}

/**
 * Generate set file
 * @param instance current object of interest
 */
function gen_set_file(instance)
{
    //Prepare set file
    //Needs to set CCONFIG to the file, not the folder, if several configs
    //live there, it will load them all.
    instance.set_text <-
/******************************************************************************/
@"#/bin/bash
#
# @(#) Load this script in environment before Enduro/X start
#
export NDRX_APPHOME="+instance.app_home+@"
export NDRX_CCONFIG="+instance.ndrx_conf+"/"+"app."+instance.prefix+@".ini
export PATH=$PATH:"+instance.ndrx_bin+@"
export CDPATH=$CDPATH:.:$NDRX_APPHOME
";
/******************************************************************************/
    print("set_file: [\n"+instance.set_text+"]");
}

/**
 * Generate ini file.
 * This contains sections:
 * - global env
 * - cctag/group envs
 * - debug settings
 * - forward queues, if any
 */
function gen_ini_file(instance)
{
    //TODO: pull in ENVFILE. If found FIELDTBLS32 or FLDTBLDIR32, translate
    //to FIELDTBLS or FLDTBLDIR.
    //Also Support #738 shall be fixed, so that we can ignore non-loadable files
    //FIELDTBLS shall be appended with Exfields. Append FLDTBLDIR with ubftab
    //of the distribution.
    instance.ini_text <-
/******************************************************************************/
@"[@global]
NDRX_CLUSTERISED=1
NDRX_CMDWAIT=1
NDRX_CONFIG="+instance.ndrx_conf+"/ndrxconfig."+instance.prefix+@".xml
NDRX_DMNLOG=${NDRX_APPHOME}/log/ndrxd.log
NDRX_DPID=${NDRX_APPHOME}/tmp/ndrxd.pid
NDRX_DQMAX=100
NDRX_IPCKEY="+instance.ipckey+@"
NDRX_LDBAL=0
NDRX_LEV=5
NDRX_LOG=${NDRX_APPHOME}/log/xadmin.log
NDRX_MSGMAX=100
NDRX_MSGSIZEMAX=56000
NDRX_NODEID="+instance.machine.nodeid+@"
NDRX_QPATH="+M_wizzard.qpath+@"
NDRX_QPREFIX=/"+instance.prefix+@"
NDRX_RNDK="+rands(8)+@"
NDRX_SRVMAX="+ M_resources["MAXSERVERS"][0]+@"
NDRX_SVCMAX="+M_resources["MAXSERVICES"][0]+@"
NDRX_TOUT="+ M_resources["SCANUNIT"][0].tointeger() 
      * M_resources["BLOCKTIME"][0].tointeger() +@"
NDRX_UBFMAXFLDS=16000
NDRX_LIBEXT="+M_wizzard.shared_lib_pfx+@"
NDRX_ULOG=${NDRX_APPHOME}/log
# TODO, replace if not found already in env:
#FIELDTBLS=Exfields
#FLDTBLDIR=${NDRX_APPHOME}/ubftab
NDRX_RTSVCMAX="+instance.rtsvcmax+@"
NDRX_RTCRTMAX="+M_resources["MAXRTDATA"][0]+@"
";
/******************************************************************************/

    /* per group / cctag settings: */
    foreach(idx,igroup in M_sections["*GROUPS"].params)
    {
        local group = igroup[0];
        //Get our groups
        if (!group.is_default &&
            get_val(group, "LMID", null)[0] == instance.lmid && group.plot)
        {
            local group_text ="[@global/"+group.name+"]";

            if ("xaswitchname" in group && "TUXEDO/QM"==group.xaswitchname)
            {
                group_text+=
@"
NDRX_XA_RES_ID="+group.rmid+@"
NDRX_XA_OPEN_STR="+group.openinfo+@"
NDRX_XA_CLOSE_STR="+group.closeinfo+@"
NDRX_XA_DRIVERLIB=libndrxxaqdisks."+M_wizzard.shared_lib_pfx+@"
; dylib needed for osx
NDRX_XA_RMLIB=libndrxxaqdisk."+M_wizzard.shared_lib_pfx+@"
NDRX_XA_LAZY_INIT=0
NDRX_XA_FLAGS=FDATASYNC;DSYNC";
/******************************************************************************/
            }
            else if ("xaswitchname" in group)
            {
                group_text+=
/******************************************************************************/
@"
NDRX_XA_RES_ID="+group.rmid+@"
NDRX_XA_OPEN_STR="+group.openinfo+@"
NDRX_XA_CLOSE_STR="+group.closeinfo+@"
# use built in switch resolver
NDRX_XA_DRIVERLIB=libndrxxatmsx."+M_wizzard.shared_lib_pfx+@"
NDRX_XA_RMLIB=-
NDRX_XA_LAZY_INIT=1
NDRX_XA_FLAGS=RECON:*:3:100;FDATASYNC;DSYNC";
/******************************************************************************/
            }

            if ("routed" in group)
            {
                group_text+="\nNDRX_RTGRP="+group.name;
            }
            
            instance.ini_text+="\n"+group_text+"\n";
            
        }
    }

    // Debugs per binary:
    instance.ini_text+="\n"+
/******************************************************************************/
@"[@debug]
#* - goes for all binaries not listed bellow
*= ndrx=3 ubf=1 tp=3 threaded=l file=${NDRX_APPHOME}/log/endurox.org
xadmin=file=${NDRX_APPHOME}/log/xadmin.log
ndrxd=file=${NDRX_APPHOME}/log/ndrxd.log
";
/******************************************************************************/
    
    //Plot server debug only once.
    local server_plotted={};
    foreach (idx, server in instance.servers) if (!server.is_default)
    {
        if (!(server.bin in server_plotted))
        {
            //Add debug entry.
            instance.ini_text+=format("%s=file=${NDRX_APPHOME}/log/%s.${NDRX_SVSRVID}.log\n", 
                server.bin, server.bin);
            server_plotted[server.bin] <-true;
        }
    }

    if (instance.restin)
    {
        instance.ini_text+=format("restincl=file=${NDRX_APPHOME}/log/restincl.rin1.log\n");
    }
    
    //Process the queues now
    foreach(idx,igroup in M_sections["*GROUPS"].params)
    {
        //Single group only supported...
        local group = igroup[0];
        //Get our groups
        if ( !group.is_default && (get_val(group, "LMID", null)[0] == instance.lmid) 
                && "qspace" in group)
        {
            instance.ini_text+="\n"+
@"[@queue/"+group.name+@"]
# Review as necessary, see q.conf man page for details
@=svcnm=@,autoq=n,tries=3,waitinit=0,waitretry=30,waitretrymax=90,memonly=n,mode=fifo,workers=1
";
            //Add forward queues
            foreach (indx,qq in group.auto_queues)
            {
                instance.ini_text+=format("%s=autoq=y", indx, indx);
                if (qq.workers!="1")
                {
                    instance.ini_text+=format(",workers=%s", qq.workers);
                }
                
                if (qq.trantime!="-1")
                {
                    instance.ini_text+=format(",txtout=%s", qq.trantime);
                }
                instance.ini_text+="\n";
            }
        }
    }

    //Add restin config, if WSL/JOLT seen
    if (instance.restin)
    {
        instance.ini_text+="\n"+
@"[@restin]
defaults={""errors"":""json2ubf"", ""conv"":""json2ubf""}

# Instance 1, see restincl manpage for the web service formats
[@restin/RIN1]
port=8080
ip=0.0.0.0
# invoke by: http://this.host:8080/SOME_SERVICE1
/SOME_SERVICE1={""svc"":""SOME_SERVICE1""}
/SOME_SERVICE2={""svc"":""SOME_SERVICE2""}
";
    }
    
    print("app.ini: [\n"+instance.ini_text+"]");

}

/**
 * Generate Enduro/X final XML configuration
 */
function gen_xml_file(instance)
{
    /* global settings */
    instance.xml_text <-
/******************************************************************************/
@"<?xml version=""1.0"" ?>
<endurox>
    <appconfig>
        <sanity>1</sanity>
        <brrefresh>5</brrefresh>
        <restart_min>1</restart_min>
        <restart_step>1</restart_step>
        <restart_max>5</restart_max>
        <restart_to_check>20</restart_to_check>
        <gather_pq_stats>Y</gather_pq_stats>
    </appconfig>
";
/******************************************************************************/

    //Process binary by binary...
    local servers_open = false;
    local tab="";
    foreach (idx, server in instance.servers)
    {
        if (server.is_default)
        {

            if (servers_open)
            {
                instance.xml_text+=
"    </servers>\n";
                tab="";
                servers_open=false;
            }
            instance.xml_text+=
"    <defaults>\n";
        }
        else
        {
            if (!servers_open)
            {
                instance.xml_text+=
"    <servers>\n";
                servers_open=true;
                tab="    ";
            }
            instance.xml_text+=
tab+"    <server name=\""+server.bin+"\">\n";
        }

        if ("autokill" in server)
        {
            instance.xml_text+=
tab+"        <autokill>"+server.autokill+"</autokill>\n";
        }
        
        if ("start_max" in server)
        {
            instance.xml_text+=
tab+"        <start_max>"+server.start_max+"</start_max>\n";
        }
        
        if ("pingtime" in server)
        {
            instance.xml_text+=
tab+"        <pingtime>"+server.pingtime+"</pingtime>\n";
        }
        
        if ("ping_max" in server)
        {
            instance.xml_text+=
tab+"        <ping_max>"+server.ping_max+"</ping_max>\n";
        }
        
        if ("end_max" in server)
        {
            instance.xml_text+=
tab+"        <end_max>"+server.end_max+"</end_max>\n";
        }
        
        if ("killtime" in server)
        {
            instance.xml_text+=
tab+"        <killtime>"+server.killtime+"</killtime>\n";
        }
        
        if ("cctag" in server)
        {
            instance.xml_text+=
tab+"        <cctag>"+server.cctag+"</cctag>\n";
        }
        
        if ("min" in server)
        {
            instance.xml_text+=
tab+"        <min>"+server.min+"</min>\n";
        }
        
        if ("max" in server)
        {
            instance.xml_text+=
tab+"        <max>"+server.max+"</max>\n";
        }
        
        if ("srvid" in server)
        {
            instance.xml_text+=
tab+"        <srvid>"+server.srvid+"</srvid>\n";
        }
        
        if ("env" in server)
        {
            instance.xml_text+=
tab+"        <env>"+server.env+"</env>\n";
        }
        
        if ("rqaddr" in server)
        {
            instance.xml_text+=
tab+"        <rqaddr>"+server.rqaddr+"</rqaddr>\n";
        }
        
        if ("respawn" in server)
        {
            instance.xml_text+=
tab+"        <respawn>"+server.respawn+"</respawn>\n";
        }
        
        if ("mindispatchthreads" in server)
        {
            instance.xml_text+=
tab+"        <mindispatchthreads>"+server.mindispatchthreads+"</mindispatchthreads>\n";
        }
        
        if ("maxdispatchthreads" in server)
        {
            instance.xml_text+=
tab+"        <maxdispatchthreads>"+server.maxdispatchthreads+"</maxdispatchthreads>\n";
        }
        
        if ("sysopt" in server)
        {
            instance.xml_text+=
tab+"        <sysopt>"+server.sysopt+"</sysopt>\n";
        }
        
        if ("appopt" in server && server.appopt!="")
        {
            instance.xml_text+=
tab+"        <appopt>"+server.appopt+"</appopt>\n";
        }
        
        if (!server.is_default && "threadstacksize" in server)
        {
            instance.xml_text+=
tab+@"        <envs><env name=""NDRX_THREADSTACKSIZE"">"+server.threadstacksize+@"</env></envs>\n";
        }
        
        if (server.is_default)
        {
            instance.xml_text+=
tab+"    </defaults>\n";
        }
        else
        {
            instance.xml_text+=
tab+"    </server>\n";
        }
        
    }

    //Terminate the servers if was open..
    if (servers_open)
    {
        instance.xml_text+=
"    </servers>\n";
        tab="";
        servers_open=false;
    }

    //Write client (restin) if needed.
    if (instance.restin)
    {
        instance.xml_text+=
@"    <clients>
          <client cmdline=""restincl"">
              <exec tag=""RESTIN"" autostart=""Y"" subsect=""RIN1"" cctag=""RIN1"" log=""${NDRX_APPHOME}/log/restincl.rin1.log""/>
          </client>
    </clients>
";
    }

    //Prepare services.
    if (instance.rtservices > 0)
    {
        //Only once
        local service_once={};
        /* global settings */
        instance.xml_text+="    <services>\n";

        //OK, plot services section.
        foreach(idx,service in M_sections["*SERVICES"].order)
        {
            local svcok = false;

            if (!service.is_default)
            {
                if (service_once)
                local range = {};
                local service_srvgrp = get_val(service, "SRVGRP", "");
                
                //Service may have no group -> affect all
                if (service_srvgrp =="")
                {
                    svcok=true;
                }
                else
                {
                    local group_lmid = get_val(
                        M_sections["*GROUPS"].params[service_srvgrp[0]][0], "LMID", null)[0];

                    if (group_lmid == instance.lmid)
                    {
                        svcok=true;
                    }
                }
            }
            else
            {
                svcok=true;
            }

            if (svcok)
            {
                if (service.name in service_once)
                {
                    //Skip this, already exported
                    continue;
                }
                
                service_once[service.name]<-true;

                if (service.is_default)
                {
                    instance.xml_text+="        <defaults";
                }
                else
                {
                    instance.xml_text+="        <service svcnm=\""+service.name+"\"";
                }
    
                if ("PRIO" in service.keywords)
                {
                    instance.xml_text+=" prio=\""+service.keywords["PRIO"][0]+"\"";
                }

                if ("ROUTING" in service.keywords)
                {
                    instance.xml_text+=" routing=\""+service.keywords["ROUTING"][0]+"\"";
                }

                if ("AUTOTRAN" in service.keywords)
                {
                    instance.xml_text+=" autotran=\""+service.keywords["AUTOTRAN"][0]+"\"";
                }

                if ("TRANTIME" in service.keywords)
                {
                    instance.xml_text+=" trantime=\""+service.keywords["TRANTIME"][0]+"\"";
                }

                //close the tag
                instance.xml_text+="/>\n";
            }
        }

        instance.xml_text+="    </services>\n";

    }

    //Prepare routing

    if ("*ROUTING" in M_sections)
    {
        local rt_started=false;

        foreach(idx,route in M_sections["*ROUTING"].params)
        {
            //Single routing supported only (afaik Tuxedo also has requires single route)
            route = route[0];
            local field = get_val(route, "FIELD", null)[0];
            local fieldtype = get_val(route, "FIELDTYPE", null)[0];
            local ranges = get_val(route, "RANGES", null)[0];
            local buftype = get_val(route, "BUFTYPE", null)[0];

            if (buftype!="FML32" && buftype!="FML")
            {
                error(format("Ignoring route [%s] as buffer type [%s] not supported", 
                        route.name, buftype));
                continue;
            }

            if (!rt_started)
            {
                instance.xml_text+="    <routing>\n";
                rt_started=true;
            }
            
            instance.xml_text+=
@"        <route routing="""+route.name+@""">
            <field>"+field+@"</field>
            <ranges>"+ranges+@"</ranges>
            <buftype>UBF</buftype>
        </route>
";

        }

        if (rt_started)
        {
            instance.xml_text+="    </routing>\n";
        }

    }
    
    instance.xml_text+="</endurox>\n";

    print("ndrxconfig.ini: [\n"+instance.xml_text+"]");
    
}

/**
 * Write configuration files to the disk
 */
function write_files()
{
        local config_exists = false;
        //Verify files (ask for overwrite, if any missing)
        foreach (idx, instance in M_instances)
        {
            if (fileexists(instance.set_file))
            {
                //print file name
                print_stdout("Configuration file exists: ["+instance.set_file+"]\n");
                config_exists = true;
            }

            if (fileexists(instance.ini_file))
            {
                //print file name
                print_stdout("Configuration file exists: ["+instance.ini_file+"]\n");
                config_exists = true;
            }
            
            if (fileexists(instance.xml_file))
            {
                //print file name
                print_stdout("Configuration file exists: ["+instance.xml_file+"]\n");
                config_exists = true;
            }
        }

        //Ask for confirmation, if needed
        if (config_exists 
                && M_y_opt != "1" 
                && 0==chk_confirm("Really overwrite Enduro/X configuration files?"))
        {
            print("Aborted configuration file generation");
            return;
        }

        //TODO: Create folders (if any missing, log created)
        //Firstly transfer the hashmap to array, sort the array, so that shortest
        //folders come first as we are going to create them (if not exists)
        
        local dirs = [];

        foreach (idx, dir in M_folder_gen)
        {
            dir.name<-idx;
            dirs.append(dir);
        }
        
        //sort
        dirs.sort(@(a,b) a.name.len() <=> b.name.len());

        //Check dirs...
        foreach (idx, dir in dirs)
        {
            if (!(fileexists(dir.name)))
            {
                print("Creating directory ["+dir.name+"]...");
                mkdir(dir.name);
                dir.created<-true;
            }
        }

        //Write files
        foreach (idx, instance in M_instances)
        {
            try
            {
                local out = file(instance.set_file,"w");
                out.writes(instance.set_text);
                out.close();
            } 
            catch (e)
            {
                print(e);
                throw(format("Cannot write [%s] file", instance.set_file));
            }

            M_files_gen.append(instance.set_file);

            //Give chmod to execute the file 
            chmod(instance.set_file, "755");

            try
            {
                local out = file(instance.ini_file,"w");
                out.writes(instance.ini_text);
                out.close();
            }
            catch (e)
            {
                print(e);
                throw(format("Cannot write [%s] file", instance.ini_file));
            }

            M_files_gen.append(instance.ini_file);

            try
            {
                local out = file(instance.xml_file,"w");
                out.writes(instance.xml_text);
                out.close();
            }
            catch (e)
            {
                print(e);
                throw(format("Cannot write [%s] file", instance.xml_file));
            }

            M_files_gen.append(instance.xml_file);
        }
        
}
/**
 * Generate Enduro/X configs. Callback from tmloadcf. At this point
 * all configs are parsed.
 */
function ex_generate(arg)
{
    local nodeid=1;

    init();

    //Open output objects for each of the machine
    if (!("*MACHINES" in M_sections))
    {
        print("No machines defined");
        return;
    }
    
    foreach(idx,val in M_sections["*MACHINES"].params) if (!val[0].is_default)
    {
        val[0].nodeid<-nodeid;
        val[0].networked<-false;
        nodeid++;
        
        //Map LMID:MACHINE
        local lmid = get_val(val[0], "LMID", null)[0];
        M_lmidmachines[lmid]<-val[0];
    }

    //Assign networking identifiers
    prep_networking();

    //Generate each node
    foreach(idx,val in M_sections["*MACHINES"].params)
    {
        local machine = val[0];

        if (machine.is_default)
        {
            continue;
        }

        local instance = {};
        instance.name <- machine.name;
        instance.lmid <- machine.keywords.LMID[0];

        if (M_l_opt!="" && instance.lmid!=M_l_opt)
        {
            print("Skipping node ["+instance.lmid+"] as -l present");
            continue;
        }

        M_instances[machine.name]<-instance;

        instance.restin <-false;
        instance.xa_used<-false;
        print("Machine: "+instance.name);

        instance.prefix <- machine.keywords["LMID"][0].tolower();
        instance.app_home <- strcommon(machine.keywords["APPDIR"][0] , 
                        machine.keywords["TUXCONFIG"][0]);
        instance.use_rel <- false;
        if (instance.app_home=="/")
        {
            //this is absolute path
            instance.app_home = machine.keywords["APPDIR"][0];
            instance.app_bin <- machine.keywords["APPDIR"][0];
            instance.app_conf <- dirname(machine.keywords["TUXCONFIG"][0]);

            instance.ndrx_conf<- instance.app_conf;
            instance.ndrx_bin <- instance.app_bin;

            instance.set_file <-format("%s/set.%s", instance.app_conf, instance.prefix);
            instance.xml_file <-format("%s/ndrxconfig.%s.xml", instance.app_conf, instance.prefix);
            instance.ini_file <-format("%s/app.%s.ini", instance.app_conf, instance.prefix);

        }
        else
        {
            //get relative path, strip off the last / from the string
            instance.app_home = rstrips(instance.app_home, "/");

            if (instance.app_home=="")
            {
                //Exception case, not nice..
                instance.app_home="/";
            }

            instance.app_bin <- strdiff(machine.keywords["APPDIR"][0],
                                            instance.app_home);
            instance.app_bin = lstrips(instance.app_bin, "/");

            instance.app_conf <- strdiff(dirname(machine.keywords["TUXCONFIG"][0]),
                                            instance.app_home);
            instance.app_conf = lstrips(instance.app_conf, "/");

            instance.use_rel = true;

            //Prepare further folders
            instance.ndrx_conf <- "${NDRX_APPHOME}/"+instance.app_conf;
            instance.ndrx_bin <- "${NDRX_APPHOME}/"+instance.app_bin;


            instance.set_file <-format("%s/%s/set.%s", instance.app_home, 
                instance.app_conf, instance.prefix);
            instance.xml_file <-format("%s/%s/ndrxconfig.%s.xml", instance.app_home, 
                instance.app_conf, instance.prefix);
            instance.ini_file <-format("%s/%s/app.%s.ini", instance.app_home, 
                instance.app_conf, instance.prefix);
        }

        instance.nodeid <- machine.nodeid;

        if (regexp("^0x.*|^0X.*").match(M_resources["IPCKEY"][0]))
        {
            instance.ipckey <- substr(M_resources["IPCKEY"][0], 2, -1);
        }
        else
        {
            instance.ipckey <- M_resources["IPCKEY"][0]
        }

        //Dump some config
        print("use_rel = "+instance.use_rel);
        print("nodeid = "+instance.nodeid);
        print("prefix = "+instance.prefix);
        print("app_home = "+instance.app_home);
        print("app_conf = "+instance.app_conf);
        print("app_bin = "+instance.app_bin);

        print("set_file = "+instance.set_file);
        print("ini_file = "+instance.ini_file);
        print("xml_file = "+instance.xml_file);

        //Load Tuxedo defaults
        if (!("BLOCKTIME" in M_resources))
        {
            M_resources["BLOCKTIME"]<-[];
            M_resources["BLOCKTIME"].append("6");
        }

        if (!("SCANUNIT" in M_resources))
        {
            M_resources["SCANUNIT"]<-[];
            M_resources["SCANUNIT"].append("10");
        }

        //Use Enduro/X default 20K
        if (!("MAXSERVICES" in M_resources) || M_resources["MAXSERVICES"][0].tointeger() < 20000)
        {
            M_resources["MAXSERVICES"]<-[];
            M_resources["MAXSERVICES"].append("20000");
        }

        if (!("MAXSERVERS" in M_resources) || M_resources["MAXSERVERS"][0].tointeger() < 10000)
        {
            M_resources["MAXSERVERS"]<-[];
            M_resources["MAXSERVERS"].append("10000");
        }

        if (!("MAXSERVERS" in M_resources) || M_resources["MAXSERVERS"][0].tointeger() < 10000)
        {
            M_resources["MAXSERVERS"]<-[];
            M_resources["MAXSERVERS"].append("10000");
        }

        //Default transaction time
        if (!("MAXTRANTIME" in M_resources))
        {
            M_resources["MAXTRANTIME"]<-[];
            M_resources["MAXTRANTIME"].append("2147483647");
        }

        if (!("MAXRTDATA" in M_resources) || M_resources["MAXRTDATA"][0].tointeger() < 102400)
        {
            M_resources["MAXRTDATA"]<-[];
            M_resources["MAXRTDATA"].append("102400");
        }

        //Calculate number of routing services, if any.
        instance.rtservices<-get_routing_services(instance);

        //resources setting
        instance.rtsvcmax<-get_routing_services(instance);

        //Use fault, if not any set.
        if (instance.rtsvcmax == 0)
        {
            instance.rtsvcmax = 1000;
        }
        else
        {
            //For performance reasons use more.
            instance.rtsvcmax *=2;
        }

        //Schedule system folders
        M_folder_gen[instance.app_home]<-{};
        M_folder_gen[instance.app_home+"/log"]<-{};
        M_folder_gen[instance.app_home+"/tmp"]<-{};

        if (instance.use_rel)
        {
            M_folder_gen[instance.app_home+"/"+instance.app_bin]<-{};
            M_folder_gen[instance.app_home+"/"+instance.app_conf]<-{};
        }
        else
        {
            M_folder_gen[instance.app_conf]<-{};
        }

        instance.machine<-machine;
        
        //Process groups
        prep_groups(instance);
    
        //Prepare ranges
        prep_free_ranges(instance);
        
        //Build server listings
        prep_servers(instance);

        //Generate file contents:
        gen_set_file(instance);
        gen_ini_file(instance);
        gen_xml_file(instance);
    }

    print(format("M_n_opt=%s", M_n_opt));
    print(format("M_y_opt=%s", M_y_opt));
    print(format("M_l_opt=%s", M_l_opt));

    if (M_n_opt!="1")
    {
        write_files();
    }
}

/**
 * Cleanup call when script have failed.
 * @param arg not used
 */
function ex_cleanup(arg)
{
    print("File cleanup...");
    //Remove created files
    foreach (idx, file in M_files_gen)
    {
        try
        {
            print("Removing ["+file+"]");
            unlink(file);
        }
        catch (e)
        {
            error(e);
        }
    }

    print("Folder cleanup...");
    //Remove created diretories...
    local dirs = [];

    foreach (idx, dir in M_folder_gen)
    {
        dir.name<-idx;
        dirs.append(dir);
    }

    //sort, reverse order, deepest dir first...
    dirs.sort(@(a,b) b.name.len() <=>a.name.len());

    //Check dirs...
    foreach (idx, dir in dirs)
    {
        if ("created" in dir)
        {
            print("Removing directory ["+dir.name+"]...");
            try
            {
                mkdir(dir.name);
            }
            catch (e)
            {
                //Just print error..
                error(e);
            }
        }
    }
}
