//
// Ubb config to Enduro/X converter
//

//Include wizard base.
compilestring(getwizardbase())();

////////////////////////////////////////////////////////////////////////////////
// UBB Config, functions called by tmloadcf as flex & bison parses.
////////////////////////////////////////////////////////////////////////////////

//
// Globals
//

//This will keep open handles
M_instances <- {};

M_wizzard <- WizardBase();

//
// Parsed UBB Config:
//
M_resources <- {};
M_sections <- {};

//Current values
M_cur_section <- {};
M_cur_default <- {};

//This is hash of arrays.
//For one parameter there may be actually several parameters with the same
//name
M_cur_param <- {};
M_values <- [];


//Folders for generation
//Each key is full path to the disk 
//with following attributes:
//.exists true|false
//.generated true|false
//Used on error termination to cleanup
M_folder_gen <- {};

//List of files generated
//Used on error termination to clean
M_files_gen <- {};

/**
 * Add resource/keyword value
 */
function tux_add_val(arg)
{
    M_values.append(arg);
}

/**
 * Add resource parameter
 */
function tux_add_res_parm(arg)
{
    M_resources[arg] <-M_values;
    M_values<-[]; //reset
}

/**
 * Add section parameter
 */
function tux_add_sect_parm(arg)
{
    local is_default=false;

    print("Adding param ["+arg+"]");

    if (arg == "DEFAULT:")
    {
        is_default=true;
    }

    param <- {};

    //Add link to previous default
    param.defaults <- M_cur_default;
    param.keywords <- {};
    param.name <- arg;
 
    //Refresh current default
    if (is_default)
    {
        param.is_default<-true;
        M_cur_default = param;
    }
    else
    {
        param.is_default<-false;
    }

    //Save current param
    M_cur_param = param;

    //Now this is array
    if (! (arg in M_cur_section.params))
    {
        M_cur_section.params[arg]<-[]
    }

    //Get this individual in the order
    M_cur_section.order.append(param);  
    //This is now array.
    M_cur_section.params[arg].append(param);

}

/**
 * Mark group as participating in routing
 */
function tux_mark_group_routed(arg)
{
    if (arg in M_sections["*GROUPS"].params 
            && !( "routed" in M_sections["*GROUPS"].params[arg]))
    {
        M_sections["*GROUPS"].params[arg][0].routed<-true;
        print("GROUP ["+arg+"] -> routed");
    }
}

/**
 * Add keyword to parameter, callback
 */
function tux_add_sect_keyw(arg)
{   
    M_cur_param.keywords[arg] <- M_values;

    if (M_cur_section.name == "*ROUTING" && arg=="RANGES")
    {
        //Parse the DDR range.
        tux_ddr_parse(M_values[0]);
    }

    M_values<-[];
}

/**
 * Add section, callback
 */
function tux_add_sect(arg)
{
    M_sections[arg] <- {};
    M_sections[arg].params <- {};
    M_sections[arg].name <- arg;
    M_sections[arg].order <- [];

    M_cur_default <- {};
    M_cur_section = M_sections[arg];
    M_cur_param  <- {};
}

////////////////////////////////////////////////////////////////////////////////
// Generator section
////////////////////////////////////////////////////////////////////////////////


/**
 * Additional initializations
 */
function init()
{
    M_wizzard.qpath = "/dev/mqueue";
    if ("FREEBSD"==getosname())
    {
        M_wizzard.qpath = "/mnt/mqueue";
    }
}

/**
 * Get default value for section param.
 * Note that platformscript does not allow to use identifier "default" as
 * variable name.
 * @param param param object of the section
 * @param keyword keyword of interest
 * @param stock_default stock default value (if param value not present, and any
 * chained default value is not found
 * @return action value read
 */
function get_val(param, keyword, stock_default)
{
    if (! (keyword in param.keywords))
    {
        //Lookup in reverse order from current default
        local dflt = param.defaults;

        while (("keywords" in dflt) && !(keyword in dflt.keywords))
        {
            //Step back to previous default
            if ("defaults" in dflt)
            {
                dflt = dflt.defaults;
            }
            else
            {
                //No more defaults in the section
                break;
            }
        }

        if ("keywords" in dflt && keyword in dflt.keywords)
        {
            return dflt.keywords[keyword];
        }
        else
        {
            if (stock_default==null)
            {
                throw("No stock "+keyword+" value available for param ["+param.name+"]");
            }
            return stock_default;
        }
    }
    else
    {
        return param.keywords[keyword];
    }
}

/**
 * Return number of services for instance used for routing
 * @param instance instance of interest
 * @return max number of routing services used
 */
function get_routing_services(instance)
{
    local cnt=0;

    foreach(idx,service in M_sections["*SERVICES"].order)
    {
        if (!service.is_default)
        {
            local range = {};
            local service_srvgrp = get_val(service, "SRVGRP", "");
            
            //Service may have no group -> affect all
            if (service_srvgrp =="")
            {
                cnt++;
            }
            else
            {
                local group_lmid = get_val(
                    M_sections["*GROUPS"].params[service_srvgrp[0]][0], "LMID", null)[0];

                if (group_lmid == instance.lmid)
                {
                    cnt++;
                }

            }
        }
    }
    print("Routing services: "+cnt);
    return cnt;
}

/**
 * Prepare free ID ranges for given instance. For upper number we take
 *  number of total servers + 2000.
 * @param instance instance of interest
 */
function prep_free_ranges(instance)
{
    //We need to register all ranges
    //All ranges must be sorted
    //The free interval must be detected
    local start = 1;
    instance.ranges<-[];

    foreach(idx,server in M_sections["*SERVERS"].order)
    {
        if (!server.is_default)
        {
            local range = {};
            local server_srvgrp = get_val(server, "SRVGRP", "");
            local group_lmid = get_val(
                M_sections["*GROUPS"].params[server_srvgrp[0]][0], "LMID", null)[0];

            if (group_lmid == instance.lmid)
            {
                //OK this is our server
                range.min <-get_val(server, "MIN", ["1"]);
                range.max <-get_val(server, "MAX", range.min);
                range.srvid <-get_val(server, "SRVID", "");

                if (range.max[0].tointeger() < range.min[0].tointeger())
                {
                    throw(format("Invalid server %s range min=%d > max=%d",
                            server.name, range.min[0].tointeger()
                            , range.max[0].tointeger()));
                }
                range.min = range.min[0].tointeger()+range.srvid[0].tointeger();
                range.max = range.max[0].tointeger()+range.srvid[0].tointeger();
                    
                //print(format("Used rang srvid: %s %d - %d", 
                //    range.srvid[0], range.min[0], range.max[0]));
                instance.ranges.append(range);
            }
        }    
    }

    instance.ranges.sort(@(a,b) a.min <=> b.min);
    instance.free_ranges <- [];

    foreach(idx,range in instance.ranges)
    {
        print(format("Used range %d - %d", 
                range.min, range.max));
    }

    //Add first range if any
    local len = instance.ranges.len();
    if (len > 0)
    {
        if (instance.ranges[0].min > 1)
        {
            local fr = {};
            fr.min <- 1;
            fr.max <- (instance.ranges[0].min - 1);
            instance.free_ranges.append(fr);
        }

        local i=0;
        for (; i<len-1; i++)
        {
            if (instance.ranges[i].max+1< instance.ranges[i+1].min)
            {
                local fr = {};
                fr.min <- (instance.ranges[i].max   + 1);
                fr.max <- (instance.ranges[i+1].min - 1);
                instance.free_ranges.append(fr);
            }
        }

        //Add some free range+10K
        local fr = {};
        fr.min <- (instance.ranges[i].max   + 1);
        fr.max <- (instance.ranges[i].max   + 1 + 10000);
        instance.free_ranges.append(fr);
    }
    else
    {
        local fr = {};
        fr.min <- 1;
        fr.max <- 10000;
        instance.free_ranges.append(fr);
    }

    foreach(idx,range in instance.free_ranges)
    {
        print(format("Free range %d - %d", 
                range.min, range.max));
    }

}

/**
 * Prepare groups of interest for this particular node.
 * Mark the group is it used or not (used if routed or have xa).
 * Prepare open/close infos / xa infos, (extract xa settings).
 */
function prep_groups(instance)
{
    foreach(idx,group in M_sections["*GROUPS"].order)
    {
        //Get our groups
        if ( !group.is_default && (get_val(group, "LMID", null)[0] == instance.lmid))
        {
            group.plot<-true;

            if ("routed" in group)
            {
                group.plot<-true;
            }

            if ("OPENINFO" in group.keywords)
            {
                //Mark that this instance uses xa.
                instance.xa_used<-true;

                group.rmid <- get_val(group, "GRPNO", null)[0];
                local openinfo = get_val(group, "OPENINFO", null)[0];

                //Get the Switch name
                local ex = regexp(@"^(.*):.*");

                local res = ex.capture(openinfo)[1];

                group.xaswitchname <-openinfo.slice(res.begin, res.end);

                print("Got switch: ["+group.xaswitchname+"]");
                
                if (group.xaswitchname== "TUXEDO/QM")
                {
                    //Special case for MQ
                    //We only need Qspace name, the data will be stored
                    // in app_home/qdata/rm<rmid>

                    ex = regexp(@"^.*:.*:(.*)");
                    res = ex.capture(openinfo)[1];
                    local qspace = openinfo.slice(res.begin,res.end);
                    group.openinfo <- "datadir=\"${NDRX_APPHOME}/qdata/"+qspace+"\",qspace=\""+qspace+"\"";
                    group.closeinfo <- "${NDRX_XA_OPEN_STR}";
                    
                    //Schedule folder for creation.
                    if ( !(instance.app_home+"/qdata" in M_folder_gen))
                    {
                        M_folder_gen[instance.app_home+"/qdata"]<-{};
                    }
                    group.qspace<-qspace;
                    group.data_folder <- instance.app_home+"/qdata/"+qspace;
                    M_folder_gen[group.data_folder]<-{};

                    //Hashmap of auto-queues served by given queue space
                    //internally may contains .trantime setting override.
                    group.auto_queues<-{};
                    group.workers<-0;

                }
                else
                {
                    ex = regexp(@"^.*:(.*)");
                    res = ex.capture(openinfo)[1];
                    //Extract the values, transform the "TUXEDO/QM"
                    group.openinfo <- openinfo.slice(res.begin,res.end);
                    local closeinfo = get_val(group, "CLOSEINFO", [""])[0];
                    
                    if (closeinfo=="")
                    {
                        group.closeinfo <- "${NDRX_XA_OPEN_STR}";
                    }
                    else
                    {
                        ex = regexp(@"^.*:(.*)");
                        res = ex.capture(closeinfo)[1];
                        group.closeinfo <- closeinfo.slice(res.begin,res.end);
                    }
                }

                //Schedule folders to be created
                if ( !(instance.app_home+"/tmlogs" in M_folder_gen))
                {
                    M_folder_gen[instance.app_home+"/tmlogs"]<-{};
                }

                group.tmlogs<-"${NDRX_APPHOME}/tmlogs/rm"+group.rmid;
                M_folder_gen[group.tmlogs]<-{};

            }

        }
    }
}

/**
 * Prepare binaries:
 * For this LMID:
 * Remove: WSL/TMSYSEVT/JSL/TMMETADATA/TMFAN/TMQFORWARD
 * Mark: if found TMSYSEVT or TMUSREVT -> tpevsrv needed.
 * Mark: If WSL or JSL used -> restincl needed (incl clients section) & cpmsrv
 * Extract: Group qspace shall be appended with automatic Qs from TMQFORWARD instances.
 * Transform: If for server -A is found, remove it. If -A is not found, add -N
 *  as Enduro/X advertises all by default.
 * Transform: TMQUEUE -> tmqueue, replace min/max=1, update clopt.
 */
function prep_servers(instance)
{
    local server_optstring = "Aa:s:e:Ghl:n:o:Pp:rtv";

    // phase 1. Get infos about the system
    foreach(idx,server in M_sections["*SERVERS"].order) if (!server.is_default)
    {
        local server_srvgrp = get_val(server, "SRVGRP", "");
        local group_lmid = "";
	if (server_srvgrp!="")
	{
            group_lmid =get_val(M_sections["*GROUPS"].params[server_srvgrp[0]][0], "LMID", "")[0];
	}

        if (group_lmid== "" || group_lmid == instance.lmid)
        {
            local remove = false;
            print("Processing binary: ["+server.name+"]");
            
            /* Detect the type of the binary */

            switch(server.name)
            {
                case "WSL":
                case "JSL":
                        instance.restin<-true;
                        remove=true;
                    break;
                case "TMSYSEVT":
                case "TMUSREVT":
                        instance.events<-true;
                        remove=true;
                    break;
                case "TMMETADATA":
                case "TMFAN":
                        remove=true;
                    break;
                case "TMQFORWARD":

                        remove=true;
                        
                        local group = M_sections["*GROUPS"].params[server_srvgrp[0]][0];
                        //Parse the group of the forward
                        //and parse the clopt of forward, so that we get
                        //queue name & 
                        //Extract min setting (used to set workers for the Q)
                        //Extract -t from clopt second group
                        //Extract -q Q1,Q2,etc. from clopt second group
                        
                        local fwd_min = get_val(server, "MIN", null)[0];
                        local fwd_clopt = get_val(server, "CLOPT", null)[0];
                            
                        //server opt string + tmqforward optstring
                        local clopt_parsed = parseclopt2(fwd_clopt, 
                                server_optstring, "q:t:ib:ednf:");

                        //assume -1 no special timeout used.
                        local trantime = "-1";

                        foreach(idx,opt in clopt_parsed.args2)
                        {
                            if (opt.opt=="t")
                            {
                                trantime= opt.val;
                                break;
                            }
                        }

                        foreach(idx,opt in clopt_parsed.args2)
                        {
                            if (opt.opt=="q")
                            {
                                //Split Q by ,
                                //And load each Q
                                local qs = split(opt.val, ",");
                                foreach (idx, qq in qs)
                                {  
                                    //Must be loaded.
                                    print(format("Adding Q [%s] to group [%s] trantime: %s",
                                                qq, group.name, trantime));
                                    group.auto_queues[qq]<-{};
                                    group.auto_queues[qq].queue<-qq;
                                    group.auto_queues[qq].trantime<-trantime;
                                    group.auto_queues[qq].workers<-fwd_min;
                                    group.workers+=fwd_min.tointeger();
                                }
                            }
                        }
                    break;
            }

            if (remove)
            {
                //remove this hash key
                if (server.name in M_sections["*SERVERS"].params)
                {
                    delete M_sections["*SERVERS"].params[server.name];
                }
                //remove this...
                M_sections["*SERVERS"].order.remove(idx);
            }
            
        }   
    }

    // phase 2. Prepare binaries into instance.servers array, each element is hash with
    // key settings for the server or default to be generated.
    
    // phase 4. Merge consecutive defaults, remove last default if no binaries follow
    
    
}

/**
 * prepare networking. This will update each
 * machine with LMID with ip/host/binding port information
 */
function prep_networking()
{   
    //TODO: Add call to getservbyname() to get port by name.
    //TODO: 
    //155.2.193.18:some-port
    //155.2.193.18:2334
    //some.domain:some-port
    //some.domain:2334
    //0x0002010101020304
    //etc..

}

/**
 * Prepare texts for instance
 * @param instance current object of interest
 */
function generate(instance)
{

    //Prepare ranges
    prep_free_ranges(instance);

    //Prepare set file
    instance.set_text <-
/******************************************************************************/
@"#/bin/bash
#
# @(#) Load this script in environment before Enduro/X start
#
export NDRX_APPHOME="+instance.app_home+@"
export NDRX_CCONFIG="+instance.ndrx_conf+@"
export PATH=$PATH:"+instance.ndrx_bin+@"
export CDPATH=$CDPATH:.:$NDRX_APPHOME
";
/******************************************************************************/
    print("set_file: ["+instance.set_text+"]");

    //Prepare ini file, global

    instance.ini_global_text <-
/******************************************************************************/
@"[@global]
NDRX_CLUSTERISED=1
NDRX_CMDWAIT=1
NDRX_CONFIG="+instance.ndrx_conf+"/ndrxconfig."+instance.prefix+@".xml
NDRX_DMNLOG=${NDRX_APPHOME}/log/ndrxd.log
NDRX_DPID=${NDRX_APPHOME}/tmp/ndrxd.pid
NDRX_DQMAX=100
NDRX_IPCKEY="+instance.ipckey+@"
NDRX_LDBAL=0
NDRX_LEV=5
NDRX_LOG=${NDRX_APPHOME}/log/xadmin.log
NDRX_MSGMAX=100
NDRX_MSGSIZEMAX=56000
NDRX_NODEID="+instance.machine.nodeid+@"
NDRX_QPATH="+M_wizzard.qpath+@"
NDRX_QPREFIX=/"+instance.prefix+@"
NDRX_RNDK="+rands(8)+@"
NDRX_SRVMAX="+ M_resources["MAXSERVERS"][0]+@"
NDRX_SVCMAX="+M_resources["MAXSERVICES"][0]+@"
NDRX_TOUT="+ M_resources["SCANUNIT"][0].tointeger() 
      * M_resources["BLOCKTIME"][0].tointeger() +@"
NDRX_UBFMAXFLDS=16000
# if needed per binary, move to CCTAG section or binary environment
NDRX_THREADSTACKSIZE=8192
NDRX_LIBEXT="+M_wizzard.shared_lib_pfx+@"
NDRX_ULOG=${NDRX_APPHOME}/log
# TODO, replace if not found already in env:
#FIELDTBLS=Exfields
#FLDTBLDIR=${NDRX_APPHOME}/ubftab
NDRX_RTSVCMAX="+instance.rtsvcmax+@"
NDRX_RTCRTMAX="+M_resources["MAXRTDATA"][0]+@"
";
/******************************************************************************/

    //Prepare ini, any groups for this particular machine
    //Remember, only those groups/cctags for which either routing is used
    //Or two phase commit is used.
    
    print("ini_file (global): ["+instance.ini_global_text+"]");

    //TODO - pre-process binaries + this shall remove any groups
    //Defined but not used by any binary or any default -> do not plot

    prep_groups(instance);

    instance.ini_groups_text<-"";
/******************************************************************************/
    //Generate groups...
    //TODO: Add DDR setting of any group
    //In case if group is not plotting, just add empty group
    //Empty group shall be set in case if process have default group defined
    //And process group is different than default, thus we should be able to
    //reset process away from default (even to empty)
    foreach(idx,group in M_sections["*GROUPS"].order)
    {
        //Get our groups
        if (!group.is_default && get_val(group, "LMID", null)[0] == instance.lmid)
        {
            local group_text ="[@global/"+group.name+"]";

            if ("xaswitchname" in group && "TUXEDO/QM"==group.xaswitchname)
            {
                group_text+=
@"
NDRX_XA_RES_ID="+group.rmid+@"
NDRX_XA_OPEN_STR="+group.openinfo+@"
NDRX_XA_CLOSE_STR="+group.closeinfo+@"
NDRX_XA_DRIVERLIB=libndrxxaqdisks."+M_wizzard.shared_lib_pfx+@"
; dylib needed for osx
NDRX_XA_RMLIB=libndrxxaqdisk."+M_wizzard.shared_lib_pfx+@"
NDRX_XA_LAZY_INIT=0
NDRX_XA_FLAGS=FDATASYNC;DSYNC";
/******************************************************************************/
            }
            else if ("xaswitchname" in group)
            {
                group_text+=
/******************************************************************************/
@"
NDRX_XA_RES_ID="+group.rmid+@"
NDRX_XA_OPEN_STR="+group.openinfo+@"
NDRX_XA_CLOSE_STR="+group.closeinfo+@"
# use built in switch resolver
NDRX_XA_DRIVERLIB=libndrxxatmsx."+M_wizzard.shared_lib_pfx+@"
NDRX_XA_RMLIB=-
NDRX_XA_LAZY_INIT=1
NDRX_XA_FLAGS=RECON:*:3:100;FDATASYNC;DSYNC";
/******************************************************************************/
            }

            if ("routed" in group)
            {
                group_text+="\nNDRX_RTGRP="+group.name;
            }

            group_text+="\n";            
            
            print("ini_file (group) [\n"+group_text+"]");
            //Add the group to the listing
            if (""==instance.ini_groups_text)
            {
                instance.ini_groups_text=group_text;
            }
            else
            {
                instance.ini_groups_text+="\n"+group_text;
            }
        }

        //Prepare TMQ queues
        //Queue names will be extracted for forward binaries (if any found)
    }

    //print("ini_file (groups): ["+instance.ini_groups_text+"]");

    //Generate debug config

    prep_servers(instance);

    instance.ini_debug_text<-
/******************************************************************************/
@"[@debug]
#* - goes for all binaries not listed bellow
*= ndrx=3 ubf=1 tp=3 file=
";
/******************************************************************************/
    //Add additional servers such as tmsrv, restincl, tpevsrv

}

/**
 * Generate Enduro/X configs. Callback from tmloadcf. At this point
 * all configs are parsed.
 */
function ex_generate(arg)
{
    local nodeid=0;

    init();

    //Open output objects for each of the machine
    if ("*MACHINES" in M_sections)
    {
        local nodeid=1;
        foreach(idx,val in M_sections["*MACHINES"].params) if (!val[0].is_default)
        {
            val[0].nodeid<-nodeid;
            nodeid++;
        }

        foreach(idx,val in M_sections["*MACHINES"].params) if (!val[0].is_default)
        {
            local machine = val[0];
            M_instances[machine.name]<-{};

            local instance = M_instances[machine.name];
            instance.name <- machine.name;
            instance.lmid <- machine.keywords.LMID[0];

            print("Machine: "+instance.name);
            
            instance.prefix <- machine.keywords["LMID"][0].tolower();
            instance.app_home <- strcommon(machine.keywords["APPDIR"][0] , 
                            machine.keywords["TUXCONFIG"][0]);
            instance.use_rel <- false;
            if (instance.app_home=="/")
            {
                instance.app_home = machine.keywords["APPDIR"][0];
                instance.app_bin <- machine.keywords["APPDIR"][0];
                instance.app_conf <- dirname(machine.keywords["TUXCONFIG"][0]);

                instance.ndrx_conf = instance.app_conf;
                instance.ndrx_bin =  instance.app_bin;
            }
            else
            {
                //get relative path, strip off the last / from the string
                instance.app_home = rstrips(instance.app_home, "/");

                if (instance.app_home=="")
                {
                    //Exception case, not nice..
                    instance.app_home="/";
                }

                instance.app_bin <- strdiff(machine.keywords["APPDIR"][0],
                                                instance.app_home);
                instance.app_bin = lstrips(instance.app_bin, "/");

                instance.app_conf <- strdiff(dirname(machine.keywords["TUXCONFIG"][0]),
                                                instance.app_home);
                instance.app_conf = lstrips(instance.app_conf, "/");

                instance.use_rel = true;

                //Prepare further folders
                instance.ndrx_conf <- "${NDRX_APPHOME}/"+instance.app_conf;
                instance.ndrx_bin <- "${NDRX_APPHOME}/"+instance.app_bin;
            }

            //Prepare some identifiers
            nodeid++;
            instance.nodeid <- nodeid;

            if (regexp("^0x.*|^0X.*").match(M_resources["IPCKEY"][0]))
            {
                instance.ipckey <- substr(M_resources["IPCKEY"][0], 2, -1);
            }
            else
            {
                instance.ipckey <- M_resources["IPCKEY"][0]
            }

            //Dump some config
            print("use_rel = "+instance.use_rel);
            print("nodeid = "+instance.nodeid);
            print("prefix = "+instance.prefix);
            print("app_home = "+instance.app_home);
            print("app_conf = "+instance.app_bin);
            print("app_bin = "+instance.app_conf);

            //Load Tuxedo defaults
            if (!("BLOCKTIME" in M_resources))
            {
                M_resources["BLOCKTIME"]<-[];
                M_resources["BLOCKTIME"].append("6");
            }

            if (!("SCANUNIT" in M_resources))
            {
                M_resources["SCANUNIT"]<-[];
                M_resources["SCANUNIT"].append("10");
            }

            //Use Enduro/X default 20K
            if (!("MAXSERVICES" in M_resources) || M_resources["MAXSERVICES"][0].tointeger() < 20000)
            {
                M_resources["MAXSERVICES"]<-[];
                M_resources["MAXSERVICES"].append("20000");
            }

            if (!("MAXSERVERS" in M_resources) || M_resources["MAXSERVERS"][0].tointeger() < 10000)
            {
                M_resources["MAXSERVERS"]<-[];
                M_resources["MAXSERVERS"].append("10000");
            }

            if (!("MAXSERVERS" in M_resources) || M_resources["MAXSERVERS"][0].tointeger() < 10000)
            {
                M_resources["MAXSERVERS"]<-[];
                M_resources["MAXSERVERS"].append("10000");
            }
            
            //Default transaction time
            if (!("MAXTRANTIME" in M_resources))
            {
                M_resources["MAXTRANTIME"]<-[];
                M_resources["MAXTRANTIME"].append("2147483647");
            }

            if (!("MAXRTDATA" in M_resources) || M_resources["MAXRTDATA"][0].tointeger() < 102400)
            {
                M_resources["MAXRTDATA"]<-[];
                M_resources["MAXRTDATA"].append("102400");
            }

            //Calculate number of routing services, if any.
            instance.rtsvcmax<-get_routing_services(instance);

            //Use fault, if not any set.
            if (instance.rtsvcmax == 0)
            {
                instance.rtsvcmax = 1000;
            }
            else
            {
                //For performance reasons use more.
                instance.rtsvcmax *=2;
            }

            //Schedule system folders
            M_folder_gen[instance.app_home]<-{};
            M_folder_gen[instance.app_home+"/log"]<-{};
            M_folder_gen[instance.app_home+"/tmp"]<-{};

            if (instance.use_rel)
            {
                M_folder_gen[instance.app_home+"/"+instance.app_bin]<-{};
                M_folder_gen[instance.app_home+"/"+instance.app_conf]<-{};
            }
            else
            {
                M_folder_gen[instance.app_conf]<-{};
            }

            //TODO: Parse networking. WHere possible for each machine assign
            //the hostname/ip_addr, and listening port (we will bind on 0.0.0.0
            //in listen mode)

            instance.machine<-machine;

            generate(instance);

        }
    }

}
